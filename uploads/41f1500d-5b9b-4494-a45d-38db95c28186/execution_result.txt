
[2025-08-16 13:32:11]
üìú Executing Code:
import pandas as pd
import requests
import os
import io

# Define the output directory and ensure it exists
output_dir = "uploads/41f1500d-5b9b-4494-a45d-38db95c28186"
os.makedirs(output_dir, exist_ok=True)

# Define file paths for the data and metadata
data_path = os.path.join(output_dir, "data.csv")
metadata_path = os.path.join(output_dir, "metadata.txt")

# URL of the Wikipedia page to scrape
url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"

# Fetch the HTML content of the page using a User-Agent to avoid blocking
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
}
response = requests.get(url, headers=headers)
response.raise_for_status()

# Use pandas to read all tables from the HTML
# The main table "Highest-grossing films" is the first one on this page
tables = pd.read_html(io.StringIO(response.text))
df = tables[0]

# Save the DataFrame to a CSV file
df.to_csv(data_path, index=False)

# Generate the metadata file
with open(metadata_path, "w", encoding="utf-8") as f:
    f.write(f"path: {data_path}\n")
    f.write(
        "description: A table of the highest-grossing films worldwide, scraped from the Wikipedia page 'List of highest-grossing films'.\n\n"
    )

    # Output of df.info()
    f.write("--- df.info() ---\n")
    buffer = io.StringIO()
    df.info(buf=buffer)
    f.write(buffer.getvalue())
    f.write("\n")

    # Column names
    f.write("--- Column Names ---\n")
    f.write(f"{df.columns.tolist()}\n\n")

    # First few rows (df.head())
    f.write("--- df.head() ---\n")
    f.write(f"{df.head().to_string()}\n\n")

    # ANSWER_FORMAT block from the user's request
    f.write("ANSWER_FORMAT:\n")
    f.write("JSON array")

----------------------------------------

[2025-08-16 13:32:14]
‚úÖ Code executed successfully after installing libraries.
----------------------------------------

[2025-08-16 13:32:49]
üìú Executing Code:
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# --- Data Loading and Cleaning ---
file_path = "uploads/41f1500d-5b9b-4494-a45d-38db95c28186/data.csv"
df = pd.read_csv(file_path)

# Clean 'Worldwide gross' column
df["Worldwide gross"] = (
    df["Worldwide gross"].replace({r"[T$,]": ""}, regex=True).astype(float)
)

# Clean 'Peak' column
df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")

# --- Question 1: How many $2 bn movies before 2023? ---
movies_2bn_before_2023 = df[
    (df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2023)
]
count_2bn_movies = len(movies_2bn_before_2023)

# --- Question 2: Earliest film over $1.5 bn? ---
movies_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
earliest_film_title = movies_1_5bn.loc[movies_1_5bn["Year"].idxmin()]["Title"]

# --- Question 3: Correlation between Rank and Peak? ---
# Drop rows with NaN in 'Peak' or 'Rank' for correlation calculation
df_corr = df[["Rank", "Peak"]].dropna()
correlation = df_corr["Rank"].corr(df_corr["Peak"])

# --- Question 4: Scatterplot of Rank vs Peak with dotted red regression line ---
# Drop rows with NaN for plotting
df_plot = df[["Rank", "Peak"]].dropna().copy()
df_plot["Peak"] = df_plot["Peak"].astype(int)

plt.figure(figsize=(10, 6))
sns.regplot(
    x="Rank",
    y="Peak",
    data=df_plot,
    scatter_kws={"alpha": 0.6},
    line_kws={"color": "red", "linestyle": "--"},
)
plt.title("Scatterplot of Rank vs Peak")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)

# Convert plot to base64
buf = io.BytesIO()
plt.savefig(buf, format="png", bbox_inches="tight")
buf.seek(0)
image_base64 = base64.b64encode(buf.read()).decode("utf-8")
plt.close()

# --- Construct Final JSON Output ---
results = [
    {"question": "How many $2 bn movies before 2023?", "answer": count_2bn_movies},
    {"question": "Earliest film over $1.5 bn?", "answer": earliest_film_title},
    {"question": "Correlation between Rank and Peak?", "answer": correlation},
    {
        "question": "Scatterplot of Rank vs Peak with dotted red regression line as base64 PNG.",
        "answer": {"image_base64": image_base64},
    },
]

# --- Save to file ---
output_path = "uploads/41f1500d-5b9b-4494-a45d-38db95c28186/result.json"
with open(output_path, "w") as f:
    json.dump(results, f, indent=4)

----------------------------------------

[2025-08-16 13:32:50]
‚ùå Error during code execution:
Traceback (most recent call last):
  File "/home/dssonali24/Project_2/task_engine.py", line 48, in run_python_code
    execute_code()
  File "/home/dssonali24/Project_2/task_engine.py", line 26, in execute_code
    exec(code, exec_globals)
  File "<string>", line 13, in <module>
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/generic.py", line 6662, in astype
    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py", line 430, in astype
    return self.apply(
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py", line 363, in apply
    applied = getattr(b, f)(**kwargs)
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py", line 784, in astype
    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py", line 237, in astype_array_safe
    new_values = astype_array(values, dtype, copy=copy)
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py", line 182, in astype_array
    values = _astype_nansafe(values, dtype, copy=copy)
  File "/home/dssonali24/Project_2/venv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py", line 133, in _astype_nansafe
    return arr.astype(dtype, copy=True)
ValueError: could not convert string to float: 'SM1922598800'

----------------------------------------

[2025-08-16 13:33:28]
üìú Executing Code:
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# --- Data Loading and Cleaning ---
file_path = "uploads/41f1500d-5b9b-4494-a45d-38db95c28186/data.csv"
df = pd.read_csv(file_path)

# Corrected cleaning for 'Worldwide gross' column
# Remove all non-digit characters to handle unexpected prefixes and symbols
df["Worldwide gross"] = df["Worldwide gross"].replace({r"[^\d]": ""}, regex=True)
# Convert to numeric, coercing any remaining invalid formats to NaN
df["Worldwide gross"] = pd.to_numeric(df["Worldwide gross"], errors="coerce")

# Clean 'Peak' column
df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")

# --- Question 1: How many $2 bn movies before 2023? ---
df_cleaned = df.dropna(subset=["Worldwide gross"])
movies_2bn_before_2023 = df_cleaned[
    (df_cleaned["Worldwide gross"] >= 2_000_000_000) & (df_cleaned["Year"] < 2023)
]
count_2bn_movies = len(movies_2bn_before_2023)

# --- Question 2: Earliest film over $1.5 bn? ---
movies_1_5bn = df_cleaned[df_cleaned["Worldwide gross"] >= 1_500_000_000]
if not movies_1_5bn.empty:
    earliest_film_title = movies_1_5bn.loc[movies_1_5bn["Year"].idxmin()]["Title"]
else:
    earliest_film_title = "No film found"

# --- Question 3: Correlation between Rank and Peak? ---
# Drop rows with NaN in 'Peak' or 'Rank' for correlation calculation
df_corr = df[["Rank", "Peak"]].dropna()
correlation = df_corr["Rank"].corr(df_corr["Peak"])

# --- Question 4: Scatterplot of Rank vs Peak with dotted red regression line ---
# Drop rows with NaN for plotting
df_plot = df[["Rank", "Peak"]].dropna().copy()
df_plot["Peak"] = df_plot["Peak"].astype(int)

plt.figure(figsize=(10, 6))
sns.regplot(
    x="Rank",
    y="Peak",
    data=df_plot,
    scatter_kws={"alpha": 0.6},
    line_kws={"color": "red", "linestyle": "--"},
)
plt.title("Scatterplot of Rank vs Peak")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)

# Convert plot to base64
buf = io.BytesIO()
plt.savefig(buf, format="png", bbox_inches="tight")
buf.seek(0)
image_base64 = base64.b64encode(buf.read()).decode("utf-8")
plt.close()

# --- Construct Final JSON Output ---
results = [
    {"question": "How many $2 bn movies before 2023?", "answer": count_2bn_movies},
    {"question": "Earliest film over $1.5 bn?", "answer": earliest_film_title},
    {"question": "Correlation between Rank and Peak?", "answer": correlation},
    {
        "question": "Scatterplot of Rank vs Peak with dotted red regression line as base64 PNG.",
        "answer": {"image_base64": image_base64},
    },
]

# --- Save to file ---
output_path = "uploads/41f1500d-5b9b-4494-a45d-38db95c28186/result.json"
with open(output_path, "w") as f:
    json.dump(results, f, indent=4)

----------------------------------------

[2025-08-16 13:33:28]
‚úÖ Code executed successfully after installing libraries.
----------------------------------------
