
[2025-08-16 13:56:13]
ðŸ“œ Executing Code:
import os
import pandas as pd
import requests
from io import StringIO

# Define the output directory
output_dir = "uploads/bf9b0b8e-f6bf-4c94-8101-0e2a96bb95f4"
os.makedirs(output_dir, exist_ok=True)

# Define file paths
data_path = os.path.join(output_dir, "data.csv")
metadata_path = os.path.join(output_dir, "metadata.txt")

# URL of the Wikipedia page
url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"

# Fetch the HTML content
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
}
response = requests.get(url, headers=headers)
html_content = response.content

# Read the HTML tables into a list of DataFrames
# The first table is the one for highest-grossing films.
tables = pd.read_html(html_content)
df = tables[0]

# --- Data Cleaning ---
# Rename columns for easier access
df.columns = ["Rank", "Peak", "Title", "Worldwide_gross", "Year", "Reference"]

# Clean the 'Worldwide_gross' column
df["Worldwide_gross"] = (
    df["Worldwide_gross"].astype(str).str.replace(r"\s*\(USD\)", "", regex=True)
)  # remove (USD)
df["Worldwide_gross"] = (
    df["Worldwide_gross"].astype(str).str.replace(r"\[.*?\]", "", regex=True)
)  # remove references
df["Worldwide_gross"] = (
    df["Worldwide_gross"]
    .str.replace("$", "", regex=False)
    .str.replace(",", "", regex=False)
)
df["Worldwide_gross"] = pd.to_numeric(df["Worldwide_gross"], errors="coerce")

# Clean the 'Year' column
df["Year"] = df["Year"].astype(str).str.extract(r"(\d{4})", expand=False)
df["Year"] = pd.to_numeric(df["Year"], errors="coerce")

# Clean Rank and Peak to be numeric
df["Rank"] = pd.to_numeric(df["Rank"], errors="coerce")
df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")

# Drop rows with NaN values in crucial columns
df.dropna(subset=["Worldwide_gross", "Year", "Rank", "Peak"], inplace=True)

# Convert columns to appropriate integer types
df = df.astype(
    {"Rank": "int64", "Peak": "int64", "Worldwide_gross": "int64", "Year": "int64"}
)

# Save the cleaned data to a CSV file
df.to_csv(data_path, index=False)

# --- Metadata Generation ---
with open(metadata_path, "w", encoding="utf-8") as f:
    f.write(f"path: {data_path}\n")
    f.write(f"description: Table of highest-grossing films scraped from Wikipedia.\n\n")

    # Capture df.info() output
    buffer = StringIO()
    df.info(buf=buffer)
    f.write("df.info():\n")
    f.write(buffer.getvalue())
    f.write("\n")

    f.write("Column names:\n")
    f.write(f"{df.columns.tolist()}\n\n")

    f.write("First few rows (df.head()):\n")
    f.write(df.head().to_string())
    f.write("\n\n")

    # Based on the user's request "Answer as JSON array"
    f.write("ANSWER_FORMAT: JSON\n")

print(f"Data saved to {data_path}")
print(f"Metadata saved to {metadata_path}")

----------------------------------------

[2025-08-16 13:56:14]
âœ… Code executed successfully after installing libraries.
----------------------------------------

[2025-08-16 13:56:59]
ðŸ“œ Executing Code:
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io

# Define file paths
data_path = "uploads/bf9b0b8e-f6bf-4c94-8101-0e2a96bb95f4/data.csv"
output_path = "uploads/bf9b0b8e-f6bf-4c94-8101-0e2a96bb95f4/result.json"

# Load the data
df = pd.read_csv(data_path)

# --- Question 1: How many $2 bn movies before 2023? ---
# Filter for movies with worldwide gross >= $2 billion and released before 2023
movies_2bn_before_2023 = df[
    (df["Worldwide_gross"] >= 2_000_000_000) & (df["Year"] < 2023)
]
num_movies_2bn_before_2023 = len(movies_2bn_before_2023)

# --- Question 2: Earliest film over $1.5 bn? ---
# Filter for movies with worldwide gross >= $1.5 billion
movies_1_5bn = df[df["Worldwide_gross"] >= 1_500_000_000]
# Sort by year to find the earliest and get its title
earliest_film_over_1_5bn = movies_1_5bn.sort_values(by="Year", ascending=True).iloc[0][
    "Title"
]

# --- Question 3: Correlation between Rank and Peak? ---
correlation_rank_peak = df["Rank"].corr(df["Peak"])

# --- Question 4: Scatterplot of Rank vs Peak with dotted red regression line ---
# Create the plot
plt.figure(figsize=(10, 6))
sns.regplot(
    x="Rank",
    y="Peak",
    data=df,
    line_kws={"color": "red", "linestyle": "--"},
    scatter_kws={"alpha": 0.7},
)
plt.title("Rank vs. Peak for Highest-Grossing Films")
plt.xlabel("Overall Rank")
plt.ylabel("Peak Position")
plt.grid(True)
plt.tight_layout()

# Convert plot to base64 string
buf = io.BytesIO()
plt.savefig(buf, format="png")
buf.seek(0)
image_base64_string = base64.b64encode(buf.read()).decode("utf-8")
plt.close()

# --- Assemble the final JSON output ---
# Structure the results in a dictionary
final_json = {
    "num_2bn_movies_before_2023": num_movies_2bn_before_2023,
    "earliest_film_over_1_5bn": earliest_film_over_1_5bn,
    "correlation_between_rank_and_peak": correlation_rank_peak,
    "images": [{"name": "rank_vs_peak_scatterplot.png", "data": image_base64_string}],
}

# Save the result to a JSON file
with open(output_path, "w") as f:
    json.dump(final_json, f, indent=4)

----------------------------------------

[2025-08-16 13:56:59]
âœ… Code executed successfully after installing libraries.
----------------------------------------
