{
    "code": "import os\nimport pandas as pd\nimport requests\nimport io\n\n# --- Setup ---\n# Create the output directory if it doesn't exist\noutput_dir = 'uploads/278a7c6e-abd9-4fd9-8070-b8415bc89c64'\nos.makedirs(output_dir, exist_ok=True)\n\n# Define file paths for data and metadata\ndata_path = os.path.join(output_dir, 'data.csv')\nmetadata_path = os.path.join(output_dir, 'metadata.txt')\n\n# --- Data Scraping and Cleaning ---\n# Scrape the table from the Wikipedia page\nurl = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\nresponse = requests.get(url)\n# Using io.StringIO to treat the html string as a file for read_html\ntables = pd.read_html(io.StringIO(response.text))\n\n# The main table is the first one on the page\ndf = tables[0]\n\n# Clean the 'Worldwide gross' column by removing non-numeric characters\n# and converting to a 64-bit integer\ndf['Worldwide gross'] = df['Worldwide gross'].astype(str).str.replace(r'[\\$,]', '', regex=True).str.replace(r'\\[.*?\\]', '', regex=True)\ndf['Worldwide gross'] = pd.to_numeric(df['Worldwide gross'], errors='coerce')\n\n# Clean the 'Year' column by extracting the four-digit year\ndf['Year'] = df['Year'].astype(str).str.extract(r'(\\d{4})', expand=False)\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n\n# Convert 'Rank' and 'Peak' to numeric types, coercing errors\ndf['Rank'] = pd.to_numeric(df['Rank'], errors='coerce')\ndf['Peak'] = pd.to_numeric(df['Peak'], errors='coerce')\n\n# Drop any rows that couldn't be cleaned properly (resulting in NaNs)\ndf.dropna(subset=['Worldwide gross', 'Year', 'Rank', 'Peak'], inplace=True)\n\n# Convert columns to the appropriate integer types for analysis\ndf = df.astype({'Worldwide gross': 'int64', 'Year': 'int', 'Rank': 'int', 'Peak': 'int'})\n\n# Select and reorder columns for clarity\ndf = df[['Rank', 'Peak', 'Title', 'Worldwide gross', 'Year']]\n\n# --- Data Storage ---\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv(data_path, index=False)\n\n# --- Metadata Generation ---\n# Write metadata to the specified file\nwith open(metadata_path, 'w', encoding='utf-8') as f:\n    f.write(f\"path: {data_path}\\n\")\n    f.write(\"description: Data on the highest-grossing films, scraped from Wikipedia.\\n\\n\")\n\n    # Capture and write df.info()\n    f.write(\"df.info():\\n\")\n    buffer = io.StringIO()\n    df.info(buf=buffer)\n    info_str = buffer.getvalue()\n    f.write(info_str)\n    f.write(\"\\n\")\n\n    # Write column names\n    f.write(\"Column names:\\n\")\n    f.write(f\"{df.columns.tolist()}\\n\\n\")\n\n    # Write the first few rows of the DataFrame\n    f.write(\"First few rows (df.head()):\\n\")\n    f.write(df.head().to_string())\n    f.write(\"\\n\\n\")\n    \n    # Add the specified answer format\n    f.write(\"ANSWER_FORMAT:\\n\")\n    f.write(\"JSON array\\n\")\n",
    "libraries": [
        "pandas",
        "requests",
        "lxml"
    ],
    "questions": [
        "How many $2 bn movies before 2023?",
        "Earliest film over $1.5 bn?",
        "Correlation between Rank and Peak?",
        "Scatterplot of Rank vs Peak with dotted red regression line as base64 PNG."
    ],
    "comment": "Step-3: Getting scrap code and metadata from llm. Tries count = %d 0"
}